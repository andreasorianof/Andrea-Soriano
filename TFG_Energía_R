# Se instalan y cargan las librerías necesarias
install.packages(c("readr", "dplyr", "ggplot2", "tidyverse", "data.table", "stringr", "textclean", "tm"))

library(readr)
library(dplyr)
library(ggplot2)
library(tidyverse)
library(data.table)
library(stringr)
library(textclean)
library(tm)

# Se cargan los datos que se van a utilizar desde un archivo CSV
df <- read_csv("TFG Analytics/energy_transition_tweets_final.csv")

#Se visualizan los datos en conjunto así como el contenido de las columnas actuales
View(df)
colnames(df)
df$tweetURL
df$date
df$tweetContent
df$userLocation
df$isUserVerified
df$replyCount
df$retweetCount
df$likeCount
df$quoteCount
df$tweetLanguage
df$sourceLabel
df$coordinates
df$place

#Se eliminan aquellas columnas que no aportan datos relevantes para realizar el análisis
df$tweetURL <- NULL
df$userLocation <- NULL
df$isUserVerified <- NULL
df$quoteCount <- NULL
df$sourceLabel <- NULL
df$coordinates <- NULL
df$place <- NULL
View(df)

# Se convierten las fechas al mismo formato
df$date <- as.Date(df$date, format="%Y-%m-%d")
df$year <- format(df$date, "%Y")
df$month <- format(df$date, "%m")
df$day <- format(df$date, "%d")


#Se realizan los principales análisis

#Se analiza en número de publicaciones por fecha 
number_tweets_bydate <- df %>% 
  group_by(date) %>% 
  summarise(count = n())

#Se genera un histograma para el número de publicaciones por fecha
ggplot(number_tweets_bydate, aes(x=date, y=count)) +
  geom_bar(stat="identity", fill="steelblue") +
  theme_minimal() +
  labs(x="Fecha", y="Número de Tweets", title="Número de Tweets por Fecha") +
  theme(axis.text.x = element_text(angle=45, hjust=1))


#Se analiza el número de publicaciones por idioma y se eliminan aquellas donde el idioma es 'und' es decir, undefined.
number_tweets_bylang_cleaned <- df %>%
  filter(tweetLanguage != "und") %>%
  group_by(tweetLanguage) %>%
  summarise(count = n()) %>%
  arrange(desc(count))  #Se ordena de forma descendente por el número de publicaciones

#Se signa el diccionario de abreviaturas a nombres completos
idiomas <- c("en" = "Inglés", "es" = "Español", "fr" = "Francés", "de" = "Alemán", "it" = "Italiano",
             "pt" = "Portugués", "ru" = "Ruso", "ja" = "Japonés", "zh" = "Chino")

#Se aplica el mapeo de los idiomas
number_tweets_bylang_cleaned$tweetLanguage <- idiomas[number_tweets_bylang_cleaned$tweetLanguage]

#Se cogen solo los top 5 idiomas con más publicaciones
number_tweets_bylang_top5 <- head(number_tweets_bylang_cleaned, 5)

#Se añade una columna para el color: rosa para 'English' y azul para los demás
number_tweets_bylang_top5 <- number_tweets_bylang_top5 %>%
  mutate(color = ifelse(tweetLanguage == "Inglés", "pink", "steelblue"))

#Se genera un histograma para el número de publicaciones por idioma
ggplot(number_tweets_bylang_top5, aes(x = reorder(tweetLanguage, -count), y = count, fill = color)) +
  geom_col(show.legend = FALSE) +
  scale_fill_identity() +
  theme_minimal() +
  labs(x = "Idioma", y = "Número de Tweets", title = "Número de Tweets por Idioma") +
  theme(axis.text.x = element_text(angle = 0, hjust = 1),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "white", colour = NA))

#Se imprime el DataFrame de los top 5 idiomas para revisar
print(number_tweets_bylang_top5)

#Se analiza de la distribución de retweets
number_retweets <- df %>%
  group_by(retweetCount) %>%
  summarise(count = n()) %>%
  filter(retweetCount > 0)  
boxplot_stats2 <- boxplot.stats(df$`retweetCount`)

#Se extraen los bigotes inferior y superior

lower_whisker <- boxplot_stats2$stats[1]

upper_whisker <- boxplot_stats2$stats[5]

#Se filtran los datos sin outliers

df_filtered2 <- df[df$`retweetCount` >= lower_whisker & df$`retweetCount` <= upper_whisker, ]

ggplot(df_filtered2, aes(x=factor(0), y=retweetCount)) +
  geom_boxplot(outlier.shape = NA, coef=1.5) +  
  scale_y_continuous() +  
  labs(x="", y="Número de Retweets", title="Distribución de Retweets por Publicación") +
  theme_minimal() +
  theme(
    axis.text.x = element_blank(), 
    axis.ticks.x = element_blank(),
    axis.text.y = element_text(size=15),  
    axis.title.y = element_text(size=17), 
    plot.title = element_text(size=17)    
  )


#Se preparan los datos para analizar los likes por cada publicación
df <- df %>%
  filter(likeCount > 0)  # Filtramos para excluir publicaciones sin 'likes'

boxplot_stats <- boxplot.stats(df$`likeCount`)

#Se extraen los bigotes inferior y superior

lower_whisker <- boxplot_stats$stats[1]

upper_whisker <- boxplot_stats$stats[5]

#S filtran los datos sin outliers

df_filtered <- df[df$`likeCount` >= lower_whisker & df$`likeCount` <= upper_whisker, ]

ggplot(df_filtered, aes(x=factor(0), y=likeCount)) +
  geom_boxplot(outlier.shape = NA, coef=1.5) +  
  scale_y_continuous() +  
  labs(x="", y="Número de Likes", title="Distribución de Likes por Publicación") +
  theme_minimal() +
  theme(
    axis.text.x = element_blank(), 
    axis.ticks.x = element_blank(),
    axis.text.y = element_text(size=15),  
    axis.title.y = element_text(size=17), 
    plot.title = element_text(size=17)    
  )


#Se saca la lista de los principales hashtags más utilizados
all_hashtags <- unlist(
  str_extract_all(df$tweetContent, "#\\w+")
)
freq_count <- as.data.frame(table(all_hashtags))
freq_count <- freq_count[order(freq_count$Freq, decreasing = TRUE),]
View(all_hashtags)

all_hashtags <- unlist(str_extract_all(df$tweetContent, "#\\w+"))
freq_count <- as.data.frame(table(all_hashtags))
colnames(freq_count) <- c("Hashtag", "Frequency")
freq_count <- freq_count[order(-freq_count$Frequency),]
top_hashtags <- head(freq_count, 20)

#Se genera el histograma con los hashtags más utilizados
ggplot(top_hashtags, aes(x=reorder(Hashtag, -Frequency), y=Frequency)) +
  geom_col(fill="steelblue") +
  labs(title="Principales Hashtags utilizados", x="Hashtags", y="Frecuencia") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle=90, hjust=1),  # Ajusta el texto del eje X para mejor visualización
    panel.grid.major = element_blank(),  # Elimina las líneas de la cuadrícula principales
    panel.grid.minor = element_blank(),  # Elimina las líneas de la cuadrícula menores
    panel.background = element_blank()   # Elimina el fondo del panel
  )


#Se realiza el preprocesamiento de los datos 

clean <- function(x) {
  if (!(is.na(x))) {
    x <- gsub("http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+", "", x) #eliminar URLs
    x <- gsub("@\\w+", "", x)  #eliminar menciones
    x <- gsub("#\\w+", "", x)  #eliminar hashtags
    x <- gsub("\\d+", "", x)   #eliminar dígitos
    x <- iconv(x, "latin1", "ASCII", sub="") # Encoding fix
    x <- gsub('\\b\\w{1,2}\\b', '', x)  #eliminar palabras cortas
    x <- gsub("\\s+", " ", x)  #reemplazar muchos espacios con uno solo
    x <- trimws(x)  # cortar espacios en blanco al principio y final del texto
  }
  return(x)
}

df$cleaned_text <- sapply(df$tweetContent, clean)


#Se saca el corpus limpio
df_filtered <- df[!(is.na(df$cleaned_text) | df$cleaned_text == ""), ]
drop <- c("tweetContent")
df_filtered <- df_filtered[, !(names(df_filtered) %in% drop)]
View(df_filtered)

#Se exporta lo obtenido a un CSV
write.csv2(df_filtered, "df_energía_as.csv", row.names = FALSE)
write.csv2(df_filtered, "C:/Usuarios/andre/Documents/df_energía_as.csv", row.names = FALSE)
